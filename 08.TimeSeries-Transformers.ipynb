{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis and Forecasting\n",
    "\n",
    "This is a series of notebooks to support lectures on _Time series analysis and forecast_.\n",
    "\n",
    "![](https://user-images.githubusercontent.com/49638680/154160268-cf39a1ec-3557-4940-8853-d06fc7a79acf.png)\n",
    "\n",
    "## Time series Forecast and Classification\n",
    "\n",
    "In paticular, over this notebook we are going to use a Recurrent Neural Network architecture with _Attention Mechanism_ in order to implement a classifier of values associated to several time series, that will play the role of features.\n",
    "\n",
    "### Some references\n",
    "\n",
    "1. [Bahdanau Attention Mechanism](https://arxiv.org/abs/1409.0473)\n",
    "2. [Transformer Architecture](https://arxiv.org/abs/1706.03762)\n",
    "3. [Adversarial Sparse Transformer for Time Series Forecasting](https://proceedings.neurips.cc/paper/2020/file/c6b8c8d762da15fa8dbbdfb6baf9e260-Paper.pdf)\n",
    "4. [Deep Transformer Models for Time Series Forecasting: The Influenza Prevalence Case](https://arxiv.org/abs/2001.08317)\n",
    "5. [The Time Series Transformer](https://towardsdatascience.com/the-time-series-transformer-2a521a0efad3)\n",
    "6. [Transformers for Time-series Forecasting](https://medium.com/mlearning-ai/transformer-implementation-for-time-series-forecasting-a9db2db5c820)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bahdanau Attention Mechanism\n",
    "\n",
    "Consider a simple encoder-decoder newtork. This model is based on the one described in the [2014 `Seq2Seq` paper by Ilya Sutskever, Oriol Vinyals and Quoc V. Le](https://research.google/pubs/pub43155/).\n",
    "\n",
    "![Image by the author](https://user-images.githubusercontent.com/49638680/156374648-1759a98c-34d2-418a-8b71-0254ca1c87ea.png)\n",
    "\n",
    "The idea is to convert an _input sequence_ - in our case a time series, but it can be a sentence to be translated (as in the paper) - into an hidden latent vector and then use this as input for the decoder part and get the _output sequence_. Again, the output sequence can be a time series forecast or the translated sentence into another language, for instance.\n",
    "For the sake of clarity and to avoid confusion, in the following we are going to refer only to _sequences_ having in mind they can be time series, texts, audio tracks, etc.\n",
    "\n",
    "To schematise:\n",
    "\n",
    "* __Encoder__: Such part of the network takes the input sequence and convert it into a fixed-length (_i.e._ the latent space dimension) encoding vector.\n",
    "\n",
    "* __Decoder__: Such part of the network takes the encoding vector and convert it into a variable-length output sequence.\n",
    "\n",
    "In principle there is no prescription about the kind of cells Encoder and Decoder network should be composed of, however, usually these are LSTM or GRU to avoid vanishing/exploding gradients.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "## The Attention Layer\n",
    "\n",
    "# Transformers: Queries, Keys, Values\n",
    "\n",
    "## Scaled dot-product Attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these kinds of tasks, a pretty straightforward procedure would be to use an autoregressive model of some kind (like *ARIMA*, *ARMAX*); these models allow us to take into account autocorrelations in a time series, and also can accept the deterministic features in the future (typically called “exogenous variables”). One limitation of ARMAX is that it is a linear model, and also one needs to specify the order of autocorrelations to be taken into account parametrically. \n",
    "LSTMs, instead, can learn nonlinear patterns, and are able to take into account autocorrelations in a nonparametric way!\n",
    "\n",
    "Furthermore, Attention model allows us to take into account longer sequences avoind the information bottleneck problem and focusing on the most relevant part of the past in order to forecast the future behaviour of the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JmVrW6rSy87F",
    "outputId": "484a0beb-acde-41f3-f5c7-cb3340ea700b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXAtbCCYG5rC"
   },
   "source": [
    "# Importing data and building dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start with a practical example of a time series and look at the [FordA dataset from the UCR/UEA archive.](https://www.cs.ucr.edu/~eamonn/time_series_data_2018/). \n",
    "\n",
    "The dataset we are using here is called FordA. The data comes from the UCR archive. The dataset contains $3601$ training instances and another $1320$ testing instances. \n",
    "Each timeseries corresponds to a measurement of engine noise captured by a motor sensor. \n",
    "\n",
    "An example task, woud be the automatic detection of the presence of a specific issue with the engine. The problem is a balanced binary classification task. The full description of this dataset can be found [here](http://www.j-wichard.de/publications/FordPaper.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "ARFJssO1k1y2",
    "outputId": "47bebadf-ac17-47b9-f770-9e3bbf46fc66"
   },
   "outputs": [],
   "source": [
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    y = data[:, 0]\n",
    "    x = data[:, 1:]\n",
    "    return x, y.astype(int)\n",
    "\n",
    "\n",
    "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
    "\n",
    "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
    "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "idx = np.random.permutation(len(x_train))\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "# In the dataset engines with issues are labeled with 1\n",
    "# the ones without issues with -1, we transform these into 0. \n",
    "y_train[y_train == -1] = 0 \n",
    "y_test[y_test == -1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal\n",
    "> detect whether an engine has an issue, analysing its noise time series. \n",
    "\n",
    "For the sake of simplicity, let’s skip a lot of data cleaning/feature engineering steps one could apply to this dataset. \n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Make a simple analysis on this dataset. Try to decompose the time series and see whether there is a recurrent behaviour in anomalous engines.\n",
    "\n",
    "## Build the model\n",
    "\n",
    "We are ready to build the model based on the attention mechanism.\n",
    "\n",
    "Our model processes a tensor of shape `(batch size, sequence_length, features)`, where `sequence_length` is the number of time steps and features is each input time series.\n",
    "\n",
    "We are going to build an Attention Layer, _i.e._ a tensorflow layer object. This is done for the sake of compatibility.\n",
    "Indeed, in the models we built previously, you can replace your classification RNN layers with this one: the inputs are fully compatible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.2):\n",
    "    # Normalization and Attention\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = tf.keras.layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = tf.keras.layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(dropout)(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main part of our model is now complete. \n",
    "\n",
    "We can stack multiple of those `transformer_encode`r blocks and we can also proceed to add the final _Multi-Layer Perceptron_ classification head. \n",
    "Apart from a stack of Dense layers, we need to reduce the output tensor of the `TransformerEncoder` part of our model down to a vector of features for each data point in the current batch. A common way to achieve this is to use a pooling layer. For this example, a `GlobalAveragePooling1D` layer is sufficient.\n",
    "\n",
    "**Note**: here we use only an attention model encoder, a fully transformer architecture would require also a decoder part. We leave the implementation of this as an exercise.\n",
    "If you feel lost, try to have a look at [this](https://www.tensorflow.org/text/tutorials/transformer) Tensorflow tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape,\n",
    "                head_size, \n",
    "                num_heads, \n",
    "                ff_dim, \n",
    "                num_transformer_blocks, \n",
    "                mlp_units, \n",
    "                dropout=0, \n",
    "                mlp_dropout=0.2):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    \n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    \n",
    "    for dim in mlp_units:\n",
    "        x = tf.keras.layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = tf.keras.layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = tf.keras.layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs, name=\"TimeSeriesTransformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate\n",
    "\n",
    "We can now go on the juicy part: training.\n",
    "\n",
    "First, we build and compile the model to have a check on dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TimeSeriesTransformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 500, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, 500, 1)       2           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_8 (MultiHe (None, 500, 1)       7169        layer_normalization_16[0][0]     \n",
      "                                                                 layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 500, 1)       0           multi_head_attention_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_16 (TFOpLa (None, 500, 1)       0           dropout_18[0][0]                 \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_17 (LayerNo (None, 500, 1)       2           tf.__operators__.add_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 500, 4)       8           layer_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 500, 4)       0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 500, 1)       5           dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_17 (TFOpLa (None, 500, 1)       0           conv1d_17[0][0]                  \n",
      "                                                                 tf.__operators__.add_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_18 (LayerNo (None, 500, 1)       2           tf.__operators__.add_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_9 (MultiHe (None, 500, 1)       7169        layer_normalization_18[0][0]     \n",
      "                                                                 layer_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 500, 1)       0           multi_head_attention_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_18 (TFOpLa (None, 500, 1)       0           dropout_20[0][0]                 \n",
      "                                                                 tf.__operators__.add_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_19 (LayerNo (None, 500, 1)       2           tf.__operators__.add_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 500, 4)       8           layer_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 500, 4)       0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 500, 1)       5           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_19 (TFOpLa (None, 500, 1)       0           conv1d_19[0][0]                  \n",
      "                                                                 tf.__operators__.add_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_20 (LayerNo (None, 500, 1)       2           tf.__operators__.add_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_10 (MultiH (None, 500, 1)       7169        layer_normalization_20[0][0]     \n",
      "                                                                 layer_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 500, 1)       0           multi_head_attention_10[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_20 (TFOpLa (None, 500, 1)       0           dropout_22[0][0]                 \n",
      "                                                                 tf.__operators__.add_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_21 (LayerNo (None, 500, 1)       2           tf.__operators__.add_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 500, 4)       8           layer_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 500, 4)       0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 500, 1)       5           dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_21 (TFOpLa (None, 500, 1)       0           conv1d_21[0][0]                  \n",
      "                                                                 tf.__operators__.add_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_22 (LayerNo (None, 500, 1)       2           tf.__operators__.add_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_11 (MultiH (None, 500, 1)       7169        layer_normalization_22[0][0]     \n",
      "                                                                 layer_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 500, 1)       0           multi_head_attention_11[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_22 (TFOpLa (None, 500, 1)       0           dropout_24[0][0]                 \n",
      "                                                                 tf.__operators__.add_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_23 (LayerNo (None, 500, 1)       2           tf.__operators__.add_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 500, 4)       8           layer_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 500, 4)       0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 500, 1)       5           dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_23 (TFOpLa (None, 500, 1)       0           conv1d_23[0][0]                  \n",
      "                                                                 tf.__operators__.add_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 500)          0           tf.__operators__.add_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          64128       global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 128)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            258         dropout_26[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 93,130\n",
      "Trainable params: 93,130\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some comments\n",
    "\n",
    "As you can see, we have ~$93$k parameters to train. The input shape is given by the whole length of the input time series. We can imagine this to be the length of the time window in the case of a series forecast.\n",
    "\n",
    "Let's move on and train such a model.\n",
    "\n",
    "We want to give an earlystopping callback, in fact it is expected that this model can easily overfit otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=10, \n",
    "                                            monitor='val_sparse_categorical_accuracy', \n",
    "                                            mode='max', \n",
    "                                            verbose=1,  \n",
    "                                            restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [es_callback]\n",
    "\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=200,\n",
    "                    batch_size=64,\n",
    "                    callbacks=callbacks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves\n",
    "Let's procede to analyse learning curves of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "l9xb1GBeAGhv",
    "outputId": "72247343-7958-4a13-e4ee-c033415cc5cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2756/2756 [==============================] - 43s 16ms/step - loss: 0.0088 - mae: 0.0956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.008798547089099884, 0.09561186283826828]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some observations\n",
    "\n",
    "In about $110$-$120$ epochs (~$25$s each on Colab with enabled GPU), the model reaches a training accuracy of ~$0.95$, validation accuracy of ~$0.84$ and a testing accuracy of ~$0.85$, without hyperparameter tuning. And that is for a model with less than $100$k parameters. Of course, parameter count and accuracy could be improved by a hyperparameter search and a more sophisticated learning rate schedule, or a different optimizer.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises \n",
    "\n",
    "1. Perform hyperparameter finetuning (you can use  a tool like the holy spirit, grid search or a framework like [optuna](https://optuna.org) if you like).\n",
    "\n",
    "2. Implement the same model using an LSTM based architecture and compare results.\n",
    "\n",
    "3. Apply the transformer architecture to a time series forecast problem\n",
    "\n",
    "---\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "The final model shows very good results on the data-set, this would outperform an implementation based on LSTM, which would suffer from short-term memory. Moreover, the architecture allows for much more rapid training, as the computations during training are done concurrently rather than sequentially. \n",
    "\n",
    "It can be concluded that the Transformer architecture, which is traditionally applied to NLP problems, has large potential in time series forecasting."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Time_series_tfp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lectures",
   "language": "python",
   "name": "lectures"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
